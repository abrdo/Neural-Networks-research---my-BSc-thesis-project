{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elso_tanulo_kod.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E6fyP6DbZHqX",
        "Q-dBtSryXr_B",
        "7v5CCVbJec7W"
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp8mr6UH9iwX"
      },
      "source": [
        "fruits = ['apple', 'banana', 'cherry']\n",
        "fruits = []\n",
        "fruits.append(\"orange\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHSAwVuZs3u4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "acbdbdda-5d03-43fb-f09b-5226a6b4f6f0"
      },
      "source": [
        "import random as rand\n",
        "\n",
        "print(\"Ugyanaz:\")\n",
        "letezikek = []\n",
        "iterations = 100000\n",
        "for it in range(iterations):  \n",
        "  birthdays = []\n",
        "  for i in range(100):\n",
        "    random_birthday = rand.randrange(366)\n",
        "    birthdays.append(random_birthday)\n",
        "  letezik = False\n",
        "  for i in range(len(birthdays)):\n",
        "    for j in range(len(birthdays)):\n",
        "      if i != j and birthdays[i] == birthdays[j]:\n",
        "        #print(bd)\n",
        "        letezik = True\n",
        "        letezikek.append(letezik)\n",
        "        break\n",
        "    if letezik:\n",
        "      break\n",
        "\n",
        "\n",
        "print len(letezikek)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ugyanaz:\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwmLCRNRZ_CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "b5df45d9-4cb5-43d2-93bf-1bb093592d2e"
      },
      "source": [
        "import random as rand\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Ugyanaz:\")\n",
        "\n",
        "end = 100\n",
        "rit = 20\n",
        "\n",
        "letezikekek = []\n",
        "for r in range(rit):\n",
        "  letezikek = []\n",
        "  iterations = 10000\n",
        "  for it in range(iterations):  \n",
        "    birthdays = []\n",
        "    for i in range(r*end/rit):\n",
        "      random_birthday = rand.randrange(366)\n",
        "      birthdays.append(random_birthday)\n",
        "    letezik = False\n",
        "    for i in range(len(birthdays)):\n",
        "      for j in range(len(birthdays)):\n",
        "        if i != j and birthdays[i] == birthdays[j]:\n",
        "          #print(bd)\n",
        "          letezik = True\n",
        "          letezikek.append(letezik)\n",
        "          break\n",
        "      if letezik:\n",
        "        break\n",
        "  letezikekek.append(len(letezikek))\n",
        "  print len(letezikek)\n",
        "\n",
        "plt.plot(range(0, 100, 5), letezikekek)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ugyanaz:\n",
            "0\n",
            "272\n",
            "1144\n",
            "2581\n",
            "4196\n",
            "5539\n",
            "6999\n",
            "8057\n",
            "8909\n",
            "9410\n",
            "9692\n",
            "9854\n",
            "9957\n",
            "9980\n",
            "9993\n",
            "9998\n",
            "9999\n",
            "10000\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff9da663450>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RViwcXqeczfp"
      },
      "source": [
        "#Machine learning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5e-Mg3VYKnT"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BhpoaPxG1mQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bc7e313e-0990-4a3f-9cd9-43d304b2eded"
      },
      "source": [
        "\n",
        "#!mkdir asd\n",
        "!cd asd\n",
        "! pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWBVQTOCThCQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "de5a15c8-4b39-4be2-ae7d-283bf3476f6f"
      },
      "source": [
        "!pwd\n",
        "%cd asd\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/asd\n",
            "[Errno 2] No such file or directory: 'asd'\n",
            "/content/asd\n",
            "/content/asd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6fyP6DbZHqX"
      },
      "source": [
        "#Add two numbers with tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4wnsUaURWBB"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOwHH-IVhFYo"
      },
      "source": [
        "##Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16seWvVDVtaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c9d9a1f0-5d2b-47be-95b6-804208d53899"
      },
      "source": [
        "num1 = tf.constant([2])\n",
        "num2 = tf.constant([11])\n",
        "\n",
        "result = tf.add(num1,num2)\n",
        "re = result\n",
        "result = 2\n",
        "\n",
        "with tf.Session() as sess1:\n",
        "  with tf.device(\"/gpu:1\"):\n",
        "    r, num =sess1.run([re, num1])\n",
        "    print(r)\n",
        "    print(num1)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13]\n",
            "Tensor(\"Const_10:0\", shape=(1,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iutrAechLVy"
      },
      "source": [
        "##Placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR75GVPvXwqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "57456b65-2e43-4b91-ea80-9fe98c127e9b"
      },
      "source": [
        "num1=tf.placeholder(tf.int32, [1])\n",
        "num2=tf.placeholder(tf.int32, [1])\n",
        "\n",
        "result = tf.add(num1, num2)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  with tf.device(\"/gpu:1\"):\n",
        "    r = sess.run([result], feed_dict={num1: [2], num2: [3]})\n",
        "    print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([5], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdOaDYgook5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c695aea9-1256-4217-94f9-2add673509d8"
      },
      "source": [
        "\n",
        "\n",
        "num1= tf.placeholder(tf.int32, [1])\n",
        "num2 = tf.placeholder(tf.int32, [1])\n",
        "\n",
        "result = tf.add(num1, num2)\n",
        "\n",
        "\n",
        "r = tf.Session().run([result], feed_dict={num1: [2], num2: [3]})\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([5], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1UFkMaehjGa"
      },
      "source": [
        "##Variable training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw6kPsxVceDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "f1f3056c-c49f-4921-d228-c6e98e4b8ade"
      },
      "source": [
        "num1 = tf.placeholder(tf.float32)\n",
        "num2 = tf.Variable([2.0], name=\"variable_to_optimize\", trainable = True)\n",
        " \n",
        "expected_output = tf.placeholder(tf.float32)\n",
        "result = tf.add(num1, num2)\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "  dif = tf.subtract(result, expected_output)\n",
        "  loss = tf.square(dif)\n",
        "  \n",
        "\n",
        "learning_rate = 0.1\n",
        "with tf.name_scope(\"optimizer\"):\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "  \n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  with tf.device(\"/gpu:1\"):\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(10):\n",
        "      _, n2, r, l = sess.run([optimizer, num2, result, loss], feed_dict={num1: [2], expected_output: [6]})\n",
        "      print(\"num2: \" + str(n2) + \" result: \"+ str(r) + \" loss: \" + str(l))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num2: [2.] result: [4.] loss: [0.0720576]\n",
            "num2: [2.4] result: [4.4] loss: [0.0720576]\n",
            "num2: [2.72] result: [4.7200003] loss: [0.0720576]\n",
            "num2: [2.976] result: [4.976] loss: [0.0720576]\n",
            "num2: [3.1808002] result: [5.1808004] loss: [0.0720576]\n",
            "num2: [3.34464] result: [5.34464] loss: [0.0720576]\n",
            "num2: [3.475712] result: [5.475712] loss: [0.0720576]\n",
            "num2: [3.5805697] result: [5.5805697] loss: [0.0720576]\n",
            "num2: [3.664456] result: [5.664456] loss: [0.0720576]\n",
            "num2: [3.7315648] result: [5.7315645] loss: [0.0720576]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyfJYrjVYg18"
      },
      "source": [
        "#Gyakorlás"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYBs45V9hht5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTW_u8ccYe_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8165ed6e-0655-4bd2-d7a8-87a8d63b73e1"
      },
      "source": [
        "a = tf.constant(1.0)\n",
        "b = tf.constant(2.0)\n",
        "c = a + b\n",
        "\n",
        "sess1 = tf.Session()\n",
        "print(sess1.run(c))\n",
        "\n",
        "with tf.Session() as sess2:\n",
        "  print(sess2.run(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0\n",
            "3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6YCSRudhjpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "105510e2-0b65-4270-9710-00433a0b7e51"
      },
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.Variable(2.0)\n",
        "desired = tf.placeholder(tf.float32)\n",
        "\n",
        "#computational graph\n",
        "result = a + b \n",
        "\n",
        "#loss\n",
        "loss = tf.square(tf.subtract(result, desired))\n",
        "#opt\n",
        "opt = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for i in range(9):\n",
        "    o, l, r, b_ = sess.run([opt, loss, result, b], feed_dict = {a: 1, desired: 11})\n",
        "    print(str(i) + '  l: ' + str(l) + '  r: ' + str(r) + '  b_: ' + str(b_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  l: 64.0  r: 3.0  b_: 2.0\n",
            "1  l: 61.465603  r: 3.16  b_: 2.16\n",
            "2  l: 59.03156  r: 3.3168  b_: 2.3168\n",
            "3  l: 56.69391  r: 3.4704642  b_: 2.4704642\n",
            "4  l: 54.448833  r: 3.621055  b_: 2.621055\n",
            "5  l: 52.292656  r: 3.7686338  b_: 2.7686338\n",
            "6  l: 50.221863  r: 3.9132612  b_: 2.9132612\n",
            "7  l: 48.23308  r: 4.054996  b_: 3.054996\n",
            "8  l: 46.323048  r: 4.1938963  b_: 3.193896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dBtSryXr_B"
      },
      "source": [
        "#Fully Connected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a27xIlcDTvlV"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Lfy8p4Two_"
      },
      "source": [
        "#read data and display data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) # we will use one hot encoding, every outputclass is a separate dimension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db0_aRkxT0pG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b1556a13-93d3-4e39-b2d3-c253e748d646"
      },
      "source": [
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape) # we have train images and train labels\n",
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape) # ans separate test iamges and labels for evaluation\n",
        "#print(mnist.train.images[0,:])\n",
        "mnist.train.labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "(55000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxP1Th0lUEO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "dcb5f975-11d9-47a1-e832-a73074bbcf03"
      },
      "source": [
        "#display an image just to get a feel what we are working on\n",
        "import matplotlib.pyplot as plt\n",
        "img= np.reshape(mnist.train.images[5,:],[28,28])\n",
        "\n",
        "plt.imshow(img,cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDFEADA5UXTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d616f1df-8769-426e-dde3-24171478b35d"
      },
      "source": [
        "print mnist.train.labels[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFdqBAvoPMKm"
      },
      "source": [
        "##Próbálás\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy3etcf1NBeu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "072d8b66-b6a6-4b13-93cb-69cfb654809b"
      },
      "source": [
        "#variable_scope\n",
        "with tf.compat.v1.variable_scope(\"foo\"):\n",
        "    with tf.compat.v1.variable_scope(\"bar\"):\n",
        "        v = tf.compat.v1.get_variable(\"v\", [1])\n",
        "        assert v.name == \"foo/bar/v:0\"\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "a2 = tf.Variable(tf.random_uniform([2, 3, 4], minval=0, maxval=10, dtype=tf.int32))\n",
        "b2 = tf.Variable(tf.random_uniform([2, 3, 4], minval=0, maxval=10, dtype=tf.int32))\n",
        "c2 = tf.add(a2,b2)\n",
        "a = tf.Variable([1,2,3] )\n",
        "a1 = tf.get_variable('a1', [1,2,3])\n",
        "b = tf.Variable([[1,2,3],[4,5,6]] )\n",
        "c = tf.add(a,b)\n",
        "print a\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "print '--------------------------------'\n",
        "print sess.run(a2)\n",
        "print sess.run(b2)\n",
        "print '________________________'\n",
        "print sess.run(c2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb2b22526f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"foo/bar/v:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAzhZ5c6I_4A"
      },
      "source": [
        "##Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv3TJqk_VwhC"
      },
      "source": [
        "#corss entropy measures similarity between two distributions. If cross entropy is zero, the two distributions are the same\n",
        "with tf.name_scope('loss'):\n",
        "\t    Loss = tf.reduce_mean( tf.losses.softmax_cross_entropy(OneHotLabels,FC)  ) # reduce_mean???\n",
        "\n",
        "with tf.name_scope('optimizer'):    \n",
        "\t    #Use ADAM optimizer this is currently the best performing training algorithm in most cases\n",
        "\t    Optimizer = tf.train.AdamOptimizer(1e-4).minimize(Loss)\n",
        "        #Optimizer = tf.train.GradientDescentOptimizer(LearningRate).minimize(Loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzDQrAt6Up1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1ff43d86-ddf4-4c3e-b711-2524749c6bc5"
      },
      "source": [
        "tf.reset_default_graph() #reset the graph\n",
        "InputData = tf.placeholder(tf.float32, [1,784] )  #input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [1,10]) #the expected outputs, labels\n",
        "\n",
        "\n",
        "NumLayers= [784,128,64,10]\n",
        "\n",
        "CurrentInput=InputData\n",
        "for i in range(len(NumLayers)-1):\n",
        "  with tf.variable_scope('layers'+str(i)):\n",
        "    \n",
        "    #súlyok egy \n",
        "    W =tf.get_variable('W', [NumLayers[i],NumLayers[i+1]])# w[784,128]\n",
        "    Layer=tf.matmul(CurrentInput,W) # matmul - matrix multiplication: inp[1,784]*w[784,128] = Layer[1,128] -----------------------------------------------------------\n",
        "    b =tf.get_variable('b', [1,NumLayers[i+1]])\n",
        "    Layer=tf.add(Layer,b)\n",
        "    Layer=tf.nn.relu(Layer)\n",
        "    \n",
        "    CurrentInput=Layer\n",
        "    print CurrentInput\n",
        "FC=CurrentInput"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"layers0/Relu:0\", shape=(1, 128), dtype=float32)\n",
            "Tensor(\"layers1/Relu:0\", shape=(1, 64), dtype=float32)\n",
            "Tensor(\"layers2/Relu:0\", shape=(1, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNyO3U9hXaUr"
      },
      "source": [
        "Init = tf.global_variables_initializer()\n",
        "with tf.Session() as Sess:\n",
        "\tSess.run(Init)\n",
        "\t\n",
        "\tStep = 1\n",
        "\t# Keep training until reach max iterations - other stopping criterion could be added\n",
        "\twhile Step < 10000:\n",
        "\t\tUsedInBatch= random.sample( range(mnist.train.images.shape[0]), 1)\n",
        "\t\tbatch_xs = mnist.train.images[UsedInBatch,:]\n",
        "\t\tbatch_ys = mnist.train.labels[UsedInBatch,:]\n",
        "\t\t_,L = Sess.run([Optimizer, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "   #Kiiras\n",
        "\t\tif (Step%100)==0:\n",
        "\t\t  print(\"Iteration: \"+str(Step))\n",
        "\t\t  print(\"Loss:\" + str(L))\n",
        "\t\tStep+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEF4Ti-gRF3N"
      },
      "source": [
        "#Convolutional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIf8Uh6YvOJI"
      },
      "source": [
        "##Read and display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KwF5FmzibFs"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGSPMttJiodL"
      },
      "source": [
        "#read data and display data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) # we will use one hot encoding, every outputclass is a separate dimension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gLRD2Kbipi0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "3258ae19-3c7c-4c0e-ca25-f062a24eedfc"
      },
      "source": [
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape) # we have train images and train labels\n",
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape) # ans separate test iamges and labels for evaluation\n",
        "#print(mnist.train.images[0,:])\n",
        "mnist.train.labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "(55000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JraNCGR0irLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a0b48af0-0b4e-43b2-ee2c-bd6d777caec9"
      },
      "source": [
        "#display an image just to get a feel what we are working on\n",
        "import matplotlib.pyplot as plt\n",
        "img= np.reshape(mnist.train.images[1,:],[28,28])\n",
        "\n",
        "plt.imshow(img,cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WufpoBAeu_uv"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hphVlE2Nis9f"
      },
      "source": [
        "#the parameters of the algorithm\n",
        "BatchLength_train= 32  #batches of 32 images are processed and averaged out\n",
        "BatchLength_test = 32\n",
        "\n",
        "NumIteration= 10000 #--------------------------15000 esetén kb 2 perc futás\n",
        "Runnings = 10\n",
        "\n",
        "Size=[28,28,1]  #size of the input image\n",
        "LearningRate=1e-4 #initial learning rate\n",
        "NumClasses = 10 #number of possible output classes\n",
        "EvalFreq = NumIteration # we will evaluate at every 1000 step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v5CCVbJec7W"
      },
      "source": [
        "##Building up the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w58fAQUMhikR"
      },
      "source": [
        "ReLU, NEM batchnorm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlWJqEkOiywi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c9be3e72-0bbd-49e8-b12b-a24ca7dd83c7"
      },
      "source": [
        "tf.reset_default_graph() #reset the graph\n",
        "InputData = tf.placeholder(tf.float32, [None]+Size )  #input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [None, NumClasses]) #the expected outputs, labels\n",
        "KeepProb = tf.placeholder(tf.float32 )  #input image\n",
        "print(InputData)\n",
        "NumKernels=[32,64,128] #a list that defined the number of layers and how many convolution kernels we have at each layer\n",
        "\n",
        "def CNNReLU(x):\n",
        "  x=tf.maximum(-1.0,x)\n",
        "  x=tf.minimum(1.0,x)\n",
        "  return x\n",
        "\n",
        "def LeakyReLU(x):\n",
        "  x = tf.maximum(x, -1.0+0.01*(x+1.0))\n",
        "  x = tf.minimum(x, 1.0-0.01*(x-1.0))\n",
        "  return x\n",
        "\n",
        "CurrentInput=InputData\n",
        "CurrentFilters=Size[2]\n",
        "LayerNum=0\n",
        "# a loop which creates all layers\n",
        "for N in NumKernels:\n",
        "    with tf.variable_scope('conv'+str(LayerNum)):\n",
        "      LayerNum+=1\n",
        "      #variables that we want to optimize\n",
        "      W =tf.get_variable('W', [3,3,CurrentFilters,N])\n",
        "      Bias = tf.get_variable('Bias', [N],initializer=tf.constant_initializer(0.0))\n",
        "      #convolution\n",
        "      ConvResult = tf.nn.conv2d(CurrentInput,W,strides=[1,1,1,1], padding='SAME')#.------\n",
        "      CurrentFilters=N\n",
        "      #we add a bias\n",
        "      ConvResult = tf.add(ConvResult,Bias)\n",
        "      #-----------------------------------------------------------------------batchnorm------------------------------------------------------------\n",
        "      '''\n",
        "      beta = tf.get_variable('beta',[N],initializer=tf.constant_initializer(0.0)) # itt NumKernel az adott rétegben taláhlató feature-ök/castornák száma\n",
        "      gamma = tf.get_variable('gamma',[N],initializer=tf.constant_initializer(1.0)) #itt is hasonló az előzőhöz\n",
        "      Mean,Variance = tf.nn.moments(ConvResult,[0,1,2]) #ConvResult az adat, amit normalizálni szeretnénk (ezt általában a convolució után szokták tenni, s így nicns szükség külön bias-ra)\n",
        "      ConvResult = tf.nn.batch_normalization(ConvResult,Mean,Variance,beta,gamma,1e-10)\n",
        "      print(ConvResult)\n",
        "      '''\n",
        "      # relu----------------------------------------------------------------------------------------------ReLU------------------------------\n",
        "      ReLU=tf.nn.relu(ConvResult)\n",
        "      #ReLU=CNNReLU(ConvResult)\n",
        "      #ReLU=LeakyReLU(ConvResult)\n",
        "      #pool\n",
        "      Pooled=tf.nn.max_pool(ReLU,ksize=[1,3,3,1],strides=[1,1,1,1],padding='SAME') #[1,3,3,1], [1,1,1,1] így cnn kompatibilis----------------------------\n",
        "      CurrentInput=Pooled\n",
        "      print(Pooled)\n",
        "    #we have generated feature maps, we will use a fully connected layer with ten neurons, one for each class\n",
        "    #the response of these neruons will represent how \"strongly\" the element belong to this class\n",
        "with tf.variable_scope('FC'):\n",
        "\t    CurrentShape=CurrentInput.get_shape()\n",
        "\t    FeatureLength = int(CurrentShape[1]*CurrentShape[2]*CurrentShape[3])\n",
        "\t    FC = tf.reshape(CurrentInput, [-1, FeatureLength])\n",
        "\t    FC = tf.nn.dropout(FC,KeepProb)\n",
        "\t    W = tf.get_variable('W',[FeatureLength,NumClasses])\n",
        "\t    FC = tf.matmul(FC, W)\n",
        "\t    Bias = tf.get_variable('Bias',[NumClasses])\n",
        "\t    FC = tf.add(FC, Bias)\n",
        "print(FC)\n",
        "print(ReLU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0620 19:45:40.677444 140445284788096 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0620 19:45:40.738684 140445284788096 deprecation.py:506] From <ipython-input-7-c9a327ab4e74>:55: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"conv0/MaxPool:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Tensor(\"conv1/MaxPool:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
            "Tensor(\"conv2/MaxPool:0\", shape=(?, 28, 28, 128), dtype=float32)\n",
            "Tensor(\"FC/Add:0\", shape=(?, 10), dtype=float32)\n",
            "Tensor(\"conv2/Relu:0\", shape=(?, 28, 28, 128), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Go7dJphsb6"
      },
      "source": [
        "CNNReLU, Batchnorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "501gWZcohsDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "99cca922-42aa-42ef-edbe-ce0fdb16d2bc"
      },
      "source": [
        "tf.reset_default_graph() #reset the graph\n",
        "InputData = tf.placeholder(tf.float32, [None]+Size )  #input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [None, NumClasses]) #the expected outputs, labels\n",
        "KeepProb = tf.placeholder(tf.float32 )  #input image\n",
        "print(InputData)\n",
        "NumKernels=[32,64,128] #a list that defined the number of layers and how many convolution kernels we have at each layer\n",
        "\n",
        "def CNNReLU(x):\n",
        "  x=tf.maximum(-1.0,x)\n",
        "  x=tf.minimum(1.0,x)\n",
        "  return x\n",
        "\n",
        "def LeakyReLU(x):\n",
        "  x = tf.maximum(x, -1.0+0.01*(x+1.0))\n",
        "  x = tf.minimum(x, 1.0-0.01*(x-1.0))\n",
        "  return x\n",
        "\n",
        "CurrentInput=InputData\n",
        "CurrentFilters=Size[2]\n",
        "LayerNum=0\n",
        "# a loop which creates all layers\n",
        "for N in NumKernels:\n",
        "    with tf.variable_scope('conv'+str(LayerNum)):\n",
        "      LayerNum+=1\n",
        "      #variables that we want to optimize\n",
        "      W =tf.get_variable('W', [3,3,CurrentFilters,N])\n",
        "      Bias = tf.get_variable('Bias', [N],initializer=tf.constant_initializer(0.0))\n",
        "      #convolution\n",
        "      ConvResult = tf.nn.conv2d(CurrentInput,W,strides=[1,1,1,1], padding='SAME')#--------VALID-->SAME\n",
        "      CurrentFilters=N\n",
        "      #we adda bias\n",
        "      ##ConvResult = tf.add(ConvResult,Bias)\n",
        "      #-----------------------------------------------------------------------batchnorm------------------------------------------------------------\n",
        "      \n",
        "      beta = tf.get_variable('beta',[N],initializer=tf.constant_initializer(0.0)) # itt NumKernel az adott rétegben taláhlató feature-ök/castornák száma\n",
        "      gamma = tf.get_variable('gamma',[N],initializer=tf.constant_initializer(1.0)) #itt is hasonló az előzőhöz\n",
        "      Mean,Variance = tf.nn.moments(ConvResult,[0,1,2]) #ConvResult az adat, amit normalizálni szeretnénk (ezt általában a convolució után szokták tenni, s így nicns szükség külön bias-ra)\n",
        "      ConvResult = tf.nn.batch_normalization(ConvResult,Mean,Variance,beta,gamma,1e-10)\n",
        "      print(ConvResult)\n",
        "      \n",
        "      # relu----------------------------------------------------------------------------------------------ReLU------------------------------\n",
        "      #ReLU=tf.nn.relu(ConvResult)\n",
        "      ReLU=CNNReLU(ConvResult)\n",
        "      #ReLU=LeakyReLU(ConvResult)\n",
        "      #pool\n",
        "      Pooled=tf.nn.max_pool(ReLU,ksize=[1,3,3,1],strides=[1,1,1,1],padding='SAME') #[1,2,2,1],strides=[1,2,2,1] VALID így cnn kompatibilis----------------------------\n",
        "      CurrentInput=Pooled\n",
        "      print(Pooled)\n",
        "    #we have generated feature maps, we will use a fully connected layer with ten neurons, one for each class\n",
        "    #the response of these neruons will represent how \"strongly\" the element belong to this class\n",
        "with tf.variable_scope('FC'):\n",
        "\t    CurrentShape=CurrentInput.get_shape()\n",
        "\t    FeatureLength = int(CurrentShape[1]*CurrentShape[2]*CurrentShape[3])\n",
        "\t    FC = tf.reshape(CurrentInput, [-1, FeatureLength])\n",
        "\t    FC = tf.nn.dropout(FC,KeepProb)\n",
        "\t    W = tf.get_variable('W',[FeatureLength,NumClasses])\n",
        "\t    FC = tf.matmul(FC, W)\n",
        "\t    Bias = tf.get_variable('Bias',[NumClasses])\n",
        "\t    FC = tf.add(FC, Bias)\n",
        "print(FC)\n",
        "print(ReLU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"conv0/batchnorm/add_1:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Tensor(\"conv0/MaxPool:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Tensor(\"conv1/batchnorm/add_1:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
            "Tensor(\"conv1/MaxPool:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
            "Tensor(\"conv2/batchnorm/add_1:0\", shape=(?, 28, 28, 128), dtype=float32)\n",
            "Tensor(\"conv2/MaxPool:0\", shape=(?, 28, 28, 128), dtype=float32)\n",
            "Tensor(\"FC/Add:0\", shape=(?, 10), dtype=float32)\n",
            "Tensor(\"conv2/Minimum:0\", shape=(?, 28, 28, 128), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJI6TrEliDNk"
      },
      "source": [
        "Loss, Optimizer, Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcQJU005i0Sc"
      },
      "source": [
        "#we use softmax to normalize the outputs of the network \n",
        "#sotfmax comes from the logistic regression and is e^i / sum(e^j) for all i and j\n",
        "#this will normlaize all the values between zero and one and the sum of values will be 1\n",
        "\n",
        "#corss entropy measures similarity between two distributions. If cross entropy is zero, the two distributions are the same\n",
        "with tf.name_scope('loss'):\n",
        "\t    Loss = tf.reduce_mean( tf.losses.softmax_cross_entropy(OneHotLabels,FC)  )\n",
        "\n",
        "with tf.name_scope('optimizer'):    \n",
        "\t    #Use ADAM optimizer this is currently the best performing training algorithm in most cases\n",
        "\t    Optimizer = tf.train.AdamOptimizer(LearningRate).minimize(Loss)\n",
        "        #Optimizer = tf.train.GradientDescentOptimizer(LearningRate).minimize(Loss)\n",
        "\n",
        "with tf.name_scope('accuracy'):\t  \n",
        "\t    CorrectPredictions = tf.equal(tf.argmax(FC, 1), tf.argmax(OneHotLabels, 1))\n",
        "\t    Accuracy = tf.reduce_mean(tf.cast(CorrectPredictions, tf.float32))\n",
        "\t      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SnUMeFBu15F"
      },
      "source": [
        "##Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC7-cBT_i3UR"
      },
      "source": [
        "accuracies=[]\n",
        "for n in range(Runnings):\n",
        "  print(\"--\"+str(n)+\"--------------------------------\")\n",
        "  \n",
        "  Init = tf.global_variables_initializer()\n",
        "\n",
        "  train_images = random.sample(range(mnist.train.images.shape[0]), 50)\n",
        "\n",
        "  with tf.Session() as Sess:\n",
        "    Sess.run(Init)\n",
        "\n",
        "    Step = 1\n",
        "    # Keep training until reach max iterations - other stopping criterion could be added\n",
        "    while Step <= NumIteration:\n",
        "      #UsedInBatch= random.sample( range(mnist.train.images.shape[0]), BatchLength) #bl db random szám generálása 1->55000-ig \n",
        "      UsedInBatch= random.sample( train_images, BatchLength_train)\n",
        "      batch_xs = mnist.train.images[UsedInBatch,:]\n",
        "      batch_ys = mnist.train.labels[UsedInBatch,:]\n",
        "      batch_xs=np.reshape(batch_xs,[BatchLength_train]+Size)\n",
        "      _,Acc,L = Sess.run([Optimizer, Accuracy, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys,KeepProb:0.8})\n",
        "      if (Step%(NumIteration/10))==0: #-------------------------------------------------\n",
        "        print(\"Iteration: \"+str(Step))\n",
        "        print(\"Accuracy:\" + str(Acc))\n",
        "        print(\"Loss:\" + str(L))\n",
        "\n",
        "      '''\n",
        "      #independent test accuracy\n",
        "      if (Step%EvalFreq)==0:\n",
        "        SumAcc=0.0\n",
        "        for i in range(0,mnist.test.images.shape[0]):\n",
        "          batch_xs = mnist.test.images[i,:]\n",
        "          batch_ys = mnist.test.labels[i,:]\n",
        "          batch_xs=np.reshape(batch_xs,[1]+Size)\n",
        "          batch_ys=np.reshape(batch_ys,[1,NumClasses])\n",
        "          a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys,KeepProb:1.0})\n",
        "          SumAcc+=a  \n",
        "        print(\"Independent Test set: \"+str(float(SumAcc)/mnist.test.images.shape[0]))\n",
        "      Step+=1\n",
        "      '''\n",
        "      \n",
        "      #independent test accuracy\n",
        "      if (Step%EvalFreq)==0:\n",
        "        SumAcc=0.0\n",
        "        for i in range(0, mnist.test.images.shape[0]-BatchLength_test, BatchLength_test):\n",
        "          batch_xs = mnist.test.images[i:i+BatchLength_test,:]\n",
        "          batch_ys = mnist.test.labels[i:i+BatchLength_test,:]\n",
        "          batch_xs = np.reshape(batch_xs,[BatchLength_test]+Size)\n",
        "          batch_ys = np.reshape(batch_ys,[BatchLength_test,NumClasses])\n",
        "          a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys, KeepProb:1.0})\n",
        "          SumAcc+=a\n",
        "        accuracies.extend([float(SumAcc)/mnist.test.images.shape[0]*BatchLength_test])\n",
        "        print(str(float(SumAcc)/mnist.test.images.shape[0]*BatchLength_test))\n",
        "      Step+=1\n",
        "      #'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJaqcobJkztg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "51d5867c-7b22-46d5-858c-4430f0a28ab8"
      },
      "source": [
        "for i in range(0, len(accuracies)):\n",
        "  print accuracies[i]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6191\n",
            "0.7388\n",
            "0.6353\n",
            "0.6524\n",
            "0.7071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK8iTnjuhFJH"
      },
      "source": [
        "accuracies=[]\n",
        "for n in range(Runnings):\n",
        "  print(\"--\"+str(n)+\"--------------------------------\")\n",
        "  \n",
        "  Init = tf.global_variables_initializer()\n",
        "\n",
        "  train_images = random.sample(range(mnist.train.images.shape[0]), 50)\n",
        "\n",
        "  with tf.Session() as Sess:\n",
        "    Sess.run(Init)\n",
        "\n",
        "    Step = 1\n",
        "    # Keep training until reach max iterations - other stopping criterion could be added\n",
        "    while Step <= NumIteration:\n",
        "      #UsedInBatch= random.sample( range(mnist.train.images.shape[0]), BatchLength) #bl db random szám generálása 1->55000-ig \n",
        "      UsedInBatch= random.sample( train_images, BatchLength_train)\n",
        "      batch_xs = mnist.train.images[UsedInBatch,:]\n",
        "      batch_ys = mnist.train.labels[UsedInBatch,:]\n",
        "      batch_xs=np.reshape(batch_xs,[BatchLength_train]+Size)\n",
        "      _,Acc,L = Sess.run([Optimizer, Accuracy, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys,KeepProb:0.8})\n",
        "      if (Step%(NumIteration/10))==0: #-------------------------------------------------\n",
        "        print(\"Iteration: \"+str(Step))\n",
        "        print(\"Accuracy:\" + str(Acc))\n",
        "        print(\"Loss:\" + str(L))\n",
        "\n",
        "      '''\n",
        "      #independent test accuracy\n",
        "      if (Step%EvalFreq)==0:\n",
        "        SumAcc=0.0\n",
        "        for i in range(0,mnist.test.images.shape[0]):\n",
        "          batch_xs = mnist.test.images[i,:]\n",
        "          batch_ys = mnist.test.labels[i,:]\n",
        "          batch_xs=np.reshape(batch_xs,[1]+Size)\n",
        "          batch_ys=np.reshape(batch_ys,[1,NumClasses])\n",
        "          a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys,KeepProb:1.0})\n",
        "          SumAcc+=a  \n",
        "        print(\"Independent Test set: \"+str(float(SumAcc)/mnist.test.images.shape[0]))\n",
        "      Step+=1\n",
        "      '''\n",
        "      \n",
        "      #independent test accuracy\n",
        "      if (Step%EvalFreq)==0:\n",
        "        SumAcc=0.0\n",
        "        for i in range(0, mnist.test.images.shape[0]-BatchLength_test, BatchLength_test):\n",
        "          batch_xs = mnist.test.images[i:i+BatchLength_test,:]\n",
        "          batch_ys = mnist.test.labels[i:i+BatchLength_test,:]\n",
        "          batch_xs = np.reshape(batch_xs,[BatchLength_test]+Size)\n",
        "          batch_ys = np.reshape(batch_ys,[BatchLength_test,NumClasses])\n",
        "          a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys, KeepProb:1.0})\n",
        "          SumAcc+=a\n",
        "        accuracies.extend([float(SumAcc)/mnist.test.images.shape[0]*BatchLength_test])\n",
        "        print(str(float(SumAcc)/mnist.test.images.shape[0]*BatchLength_test))\n",
        "      Step+=1\n",
        "      #'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W09NYEbDK4Aq"
      },
      "source": [
        "#Hasznosságok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfYjyDfaI2LU"
      },
      "source": [
        "##tf.Variable() vs tf.get_variable()\n",
        "tf.Variable(init_value, name= optional)\n",
        "\n",
        "tf.get_variable() (initializer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rjddjtsIo_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "62bb7792-b9bc-4fa4-bc3d-c439966645c8"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "a0 =tf.Variable([[2,2,2],[2,2,2]]) # inicializálás az alap paraméter, name = optional\n",
        "a = tf.get_variable('a1', [2,3])#, initializer = tf.constant_initializer(3.0)) #--ha nincs initializer akkor a default init. random valuekkal tölti fel a  variable-t\n",
        "                                #  initializer = tf.random_initializer( vannak paraméterei)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "#a_val = sess.run(a.initializer)\n",
        "a_val = sess.run(a)\n",
        "print a_val\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8bb8a01bc94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma0\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# inicializálás az alap paraméter, name = optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, initializer = tf.constant_initializer(3.0)) #--ha nincs initializer akkor a default init. random valuekkal tölti fel a  variable-t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0;31m#  initializer = tf.random_initializer( vannak paraméterei)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i7EMTF6Hjsn"
      },
      "source": [
        "##Get variable by name\n",
        "v1 = sess.graph.get_tensor_by_name(\"foo/v:0\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZha83DsgySJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "945b3b65-3e84-4bc8-b935-2ef4c4cd1d31"
      },
      "source": [
        "#--GET VALUE OF VARIABLE from var_scope by NAME\n",
        "\n",
        "  # 1.) reuse varscope\n",
        "with tf.variable_scope('foo'):\n",
        "  v = tf.get_variable('v', [1])\n",
        "\n",
        "with tf.variable_scope(\"foo\", reuse=True):\n",
        "    v1 = tf.get_variable(\"v\")\n",
        "    \n",
        "  # 2.) In sesssion with sess.graph.get_tensor_by_name(\"foo/v:0\")\n",
        "sess = tf.Session()\n",
        "v1 = sess.graph.get_tensor_by_name(\"foo/v:0\") #----sess.graph.get_tensor_by_name(\"foo/v:0\") :))) ---------------------\n",
        "sess.run(tf.global_variables_initializer())\n",
        "v1_val = sess.run(v1)\n",
        "print v1_val\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.59134656 -0.48534626  1.0630517 ]\n",
            " [-0.593993   -0.26181072 -0.2747861 ]]\n",
            "[-0.6413442]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjHxN1qZXhmt"
      },
      "source": [
        "\n",
        "# MatchNet graph indent phenomenon\n",
        "\n",
        "*  nem dob hibát az 'FC' name_scope utáni get_variable-öknél, hogy a változó már létezik, és nincs reuse\n",
        "*  Érdekes jelenség, hogy ha bárhova beírok bármit a 'FC' namescope után és a return FC előtt, a rákövetkező sorra azt írja, hogy \"unexpected indentation\"\n",
        "* HEUREKA: ha kitörlöm a 'TaBokat' (amik nem biztos h TABok) és újraütöm őkat, akkor már dobja a hibát.\n",
        "          Ezek szerint alapból **benne van a W és Bias az FC-ben**, \n",
        "          így nem kell újratanítani a hálót. :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soVsuElZU8sH"
      },
      "source": [
        "##Itt ezzel szemben normálisan dobja a hibákat:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXPQDLVJJz9c"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "def func(First):\n",
        "  a = 2\n",
        "  with tf.variable_scope(\"alma\", reuse = not First) as varscope:\n",
        "    tf.get_variable('in_scope', [2,3], initializer = tf.constant_initializer(2))\n",
        "  tf.get_variable('out_scope', [2,3], initializer = tf.constant_initializer(2))\n",
        "  return a\n",
        "  \n",
        "func(First = True)\n",
        "func(First = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU045g3ZSYrv"
      },
      "source": [
        "###Param"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmcqYQC55tO2"
      },
      "source": [
        "train_nums = [2, 3, 4] # 3elemű, növekvő sorrned  #beégetve a gráfnál, illetve az optim-nál (megoldás: rekurzív ciklus)\n",
        "test_nums = [7, 8, 9]\n",
        "\n",
        "#Iterations\n",
        "TrainIter=5000\n",
        "OptIter = 100 # queries per suppSets\n",
        "ValidIter = 5000\n",
        "\n",
        "\n",
        "\n",
        "#Graph params:\n",
        "batchS=32\n",
        "size=[28,28,1] # 28*28 1 csatornás\n",
        "nKernels = [16, 32, 64]\n",
        "learning_rate=1e-4\n",
        "VectorLength=16\n",
        "nSupp=1 #beégetve az optim-nál és utána"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eyzRJJJUiFC"
      },
      "source": [
        "###Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OTn9_VXXhm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "c0d570a4-1c36-48cf-fa17-2603835b474f"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Support information - matrix\n",
        "s_imgs = tf.placeholder(tf.float32, [batchS, len(train_nums), nSupp]+size, name = \"s_imgs_ph\")   # batch size, n classes, n supp imgs / class\n",
        "\n",
        "# Query Information - vector\n",
        "q_img = tf.placeholder(tf.float32, [batchS]+size, name = \"q_img_ph\")    # batch size\n",
        "q_label = tf.placeholder(tf.int32, [batchS, len(train_nums)], name = \"q_label_ph\") # batch size, number of categories\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"### Network Function\n",
        "Call for each support image (row of the support matrix) and for the query image.\n",
        "\"\"\"\n",
        "\n",
        "def create_network(img, size, First = False):\n",
        "  currInp = img\n",
        "  layer = 0\n",
        "  currFilt = size[2]\n",
        "  for k in nKernels: #[k0 = 16, k1 = 32, k3 = 64]\n",
        "    with tf.variable_scope('conv'+str(layer), reuse = not First) as varscope:\n",
        "      layer += 1\n",
        "      weight = tf.get_variable('weight', [3,3,currFilt,k])   # make parameters! \n",
        "      currFilt = k\n",
        "      bias = tf.get_variable('bias', [k], initializer=tf.constant_initializer(0.0))\n",
        "      convR = tf.nn.conv2d(currInp, weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "      convR = tf.add(convR, bias)\n",
        "      reluR = tf.nn.relu(convR)\n",
        "      poolR = tf.nn.max_pool(reluR, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "      currInp = poolR\n",
        "  #add a fully connected at the end of the network this could modify the feature vector\n",
        "  with tf.variable_scope('FC', reuse = not First) as varscope:\n",
        "  \tCurrentShape=currInp.get_shape()\n",
        "\tFeatureLength = int(CurrentShape[1]*CurrentShape[2]*CurrentShape[3])\n",
        "\tFC = tf.reshape(currInp, [-1,FeatureLength])\n",
        "\tW = tf.get_variable('W',[FeatureLength,VectorLength])\n",
        "\tFC = tf.matmul(FC, W)\n",
        "\tBias = tf.get_variable('Bias',[VectorLength])\n",
        "\tFC = tf.add(FC, Bias)\n",
        "\tFC = tf.reshape(FC, [batchS,VectorLength,1,1])\n",
        "  return FC\n",
        "\n",
        "\n",
        "\n",
        "query_features = create_network(q_img, size, First = True)\n",
        "print query_features\n",
        "\n",
        "\n",
        "\n",
        "support_list = []\n",
        "query_list = []\n",
        "\n",
        "\n",
        "for k in range(len(train_nums)):#--------------------\n",
        "  slist=[]\n",
        "  qlist=[]\n",
        "  for i in range(nSupp):\n",
        "    slist.append(create_network(s_imgs[:, k, i, :, :, :], size))\n",
        "    qlist.append(query_features)\n",
        "  slist = tf.stack(slist)\n",
        "  qlist = tf.stack(qlist) \n",
        "  support_list.append(slist)\n",
        "  query_list.append(qlist)\n",
        "  \n",
        "query_repeat = tf.stack(query_list)\n",
        "supports = tf.stack(support_list)\n",
        "print query_repeat\n",
        "print supports\n",
        "\n",
        "\n",
        "\"\"\"### Loss\n",
        "Cosine distance calculation  \n",
        "Application of softmax  \n",
        "Minimize loss\n",
        "\"\"\"\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "  dotProduct = tf.reduce_sum(tf.multiply(query_repeat, supports), [3,4,5])\n",
        "  supportsMagn = tf.reduce_sum(tf.square(supports), [3,4,5])\n",
        "  #supportsMagn = tf.reduce_sum(tf.square(supports), [3,4,5])\n",
        "  cosDist = dotProduct / tf.clip_by_value(supportsMagn, 1e-10, float(\"inf\"))\n",
        "  print cosDist\n",
        "  # per support\n",
        "  cosDist = tf.transpose(cosDist,[2,0,1])\n",
        "  print cosDist\n",
        "  #meancosDist per class:\n",
        "  MeanCosDist=  tf.reduce_mean(cosDist,2)\n",
        "  #maxcosDist per class:\n",
        "  MaxCostDist = tf.reduce_max(cosDist,2)\n",
        "\n",
        "\n",
        "  probs = tf.nn.softmax(MeanCosDist)  # defaults to last dimension\n",
        "\n",
        "  loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=MeanCosDist, labels=q_label))  # check if it's OK\n",
        "  print \"----------\"\n",
        "  print loss\n",
        "  \n",
        "  \n",
        "with tf.name_scope(\"optimizer\"):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "  \n",
        "\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "  max_class = tf.argmax(MaxCostDist, 1)\n",
        "  max_label = tf.argmax(q_label, 1)  \n",
        "  \n",
        "  total = tf.equal(max_class, max_label) \n",
        "  accuracy = tf.reduce_mean(tf.cast(total, tf.float32))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"FC/Reshape_1:0\", shape=(32, 16, 1, 1), dtype=float32)\n",
            "Tensor(\"stack_6:0\", shape=(3, 1, 32, 16, 1, 1), dtype=float32)\n",
            "Tensor(\"stack_7:0\", shape=(3, 1, 32, 16, 1, 1), dtype=float32)\n",
            "Tensor(\"loss/div:0\", shape=(3, 1, 32), dtype=float32)\n",
            "Tensor(\"loss/transpose:0\", shape=(32, 3, 1), dtype=float32)\n",
            "----------\n",
            "Tensor(\"loss/Sum_2:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKz-bUq1LHgp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}