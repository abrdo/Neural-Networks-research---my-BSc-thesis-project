{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "234_789_EFOP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmFJFIuWYhQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b9e5f9eb-cef5-43b6-cffe-e0e09dd73ba8"
      },
      "source": [
        "import numpy as np\n",
        "vv = np.array([3,2,6])\n",
        "vm = np.array([[3,3,6]])\n",
        "m = np.array([[8,7,6], [2,4,6], [6,3,1]])\n",
        "#n = np.array([[8,7,6], [2,4,6], [6,3,1]])\n",
        "np.matmul(vv,m)\n",
        "np.transpose(vv)\n",
        "vm.T\n",
        "vv.shape\n",
        "np.array(np.random.rand(3))\n",
        "1-m\n",
        "vv-vm\n",
        "np.transpose(vm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [3],\n",
              "       [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJfbO4FtYJdJ"
      },
      "source": [
        "#Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf1UgerHYJdT"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from google.colab import files\n",
        "!mkdir ACCs\n",
        "#!rm -rf ACCs\n",
        "!mkdir model\n",
        "tKEZDET = time.time()\n",
        "FullTime = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv5oEbHNYJdj"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzK9V1x8YJdm"
      },
      "source": [
        "changing = \"opt\"\n",
        "trainID = 0  \n",
        "OptID = 0\n",
        "\n",
        "trainID_load = 0\n",
        "if 10 <= trainID:\n",
        "  nulls = \"\"\n",
        "else:\n",
        "  nulls = \"0\"\n",
        "\n",
        "if 10 <= OptID:\n",
        "  nullso = \"\"\n",
        "else:\n",
        "  nullso = \"0\"\n",
        "\n",
        "download = True\n",
        "\n",
        "#Parameters of the SETs:\n",
        "train_nums = [2, 3, 4] # 3elemű, növekvő sorrned  #beégetve a gráfnál, illetve az optim-nál (megoldás: rekurzív ciklus)\n",
        "test_nums = [7, 8, 9]\n",
        "nValid =  1000 #beégetve a SET létrehozásnál!\n",
        "nOptq = 1000\n",
        "\n",
        "nOpt =  15 # per class\n",
        "#Iterations\n",
        "TrainIter=5000\n",
        "Iterations = 10 # ennyiszer fut le a PROGRAM\n",
        "#OptIter = 100 # queries per suppSets ----- ez egy lett. --32 képet nézünk meg az OptImgs-ből egy supp sethez\n",
        "ValidIter = 5000\n",
        "\n",
        "\n",
        "#Graph params:\n",
        "batchS=32\n",
        "size=[28,28,1]\n",
        "nKernels = [16, 32, 64]\n",
        "learning_rate=1e-4\n",
        "VectorLength=16\n",
        "nSupp=1 #beégetve az optim-nál és utána"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTgdC3hgYJdt"
      },
      "source": [
        "##Creating the SETs &ClassIndices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgffgFlrYJdv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "317c6ec4-d6ca-46b3-b0f9-1a9836e50007"
      },
      "source": [
        "#read data and display data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True) # we will use one hot encoding, every outputclass is a separate dimension\n",
        "test_images = np.concatenate((mnist.test.images, mnist.train.images[30000:55000]), axis = 0)\n",
        "train_images = mnist.train.images[:30000]\n",
        "test_labels = np.concatenate((mnist.test.labels, mnist.train.labels[30000:55000]), axis = 0)\n",
        "train_labels = mnist.train.labels[:30000]\n",
        "\n",
        "INTlabels=np.argmax(train_labels, 1) #one_hot-ból int-es labels-et csinál\n",
        "INTlabels_t=np.argmax(test_labels, 1) #one_hot-ból int-es labels-et csinál\n",
        "\n",
        "#Construating the SETs\n",
        "   #Train\n",
        "TrainInd2 = INTlabels == train_nums[0] #train_nums frissítése!!! --már nem kell :)\n",
        "TrainInd3 = INTlabels == train_nums[1]\n",
        "TrainInd4 = INTlabels == train_nums[2]\n",
        "TrainInd23 = np.maximum(TrainInd2, TrainInd3)\n",
        "TrainIndices = np.maximum(TrainInd23, TrainInd4)\n",
        "\n",
        "TrainImgs = train_images[TrainIndices]\n",
        "TrainLabels = INTlabels[TrainIndices]\n",
        "TrainImgs = TrainImgs[:30000, :]\n",
        "TrainLabels = TrainLabels[:30000]\n",
        "TrainLabels_1h = train_labels[TrainIndices, train_nums[0]:train_nums[-1]+1]\n",
        "\n",
        "#TESTIndices_______________________________________________________________________________________\n",
        "Ind0 = INTlabels_t == test_nums[0]\n",
        "Ind1 = INTlabels_t == test_nums[1]\n",
        "Ind2 = INTlabels_t == test_nums[2]\n",
        "#Ind01 = np.maximum(Ind0, Ind1)\n",
        "#TESTIndices = np.maximum(Ind01, Ind1)\n",
        "\n",
        "#TESTImgs, TLabels, TLabels_1h\n",
        "TESTImgs0 = test_images[Ind0]\n",
        "TESTImgs1 = test_images[Ind1]\n",
        "TESTImgs2 = test_images[Ind2]\n",
        "TESTLabels0 = INTlabels_t[Ind0]\n",
        "TESTLabels1 = INTlabels_t[Ind1]\n",
        "TESTLabels2 = INTlabels_t[Ind2]\n",
        "TESTLabels_1h0 = test_labels[Ind0, test_nums[0]:test_nums[-1]+1]\n",
        "TESTLabels_1h1 = test_labels[Ind1, test_nums[0]:test_nums[-1]+1]\n",
        "TESTLabels_1h2 = test_labels[Ind2, test_nums[0]:test_nums[-1]+1]\n",
        "\n",
        "\n",
        "#Valid ugyanez, csak 1000!!------------------------------------------------\n",
        "#ValidImgs\n",
        "ValidImgs0 = TESTImgs0[:nValid, :]\n",
        "ValidImgs1 = TESTImgs1[:nValid, :]\n",
        "ValidImgs2 = TESTImgs2[:nValid, :]\n",
        "ValidImgs = np.concatenate((ValidImgs0, ValidImgs1, ValidImgs2), axis=0)\n",
        "#ValidLabels_1h\n",
        "ValidLabels_1h0 = TESTLabels_1h0[:nValid, :]\n",
        "ValidLabels_1h1 = TESTLabels_1h1[:nValid, :]\n",
        "ValidLabels_1h2 = TESTLabels_1h2[:nValid, :]\n",
        "ValidLabels_1h = np.concatenate((ValidLabels_1h0, ValidLabels_1h1, ValidLabels_1h2), axis=0)\n",
        "#ValidLabels\n",
        "ValidLabels0 = TESTLabels0[:nValid]\n",
        "ValidLabels1 = TESTLabels1[:nValid]\n",
        "ValidLabels2 = TESTLabels2[:nValid]\n",
        "ValidLabels = np.concatenate((ValidLabels0, ValidLabels1, ValidLabels2), axis=0)\n",
        "\n",
        "#Opt-------------------------------------------------------------------------\n",
        "#OptImgs\n",
        "OptImgs0 = TESTImgs0[nValid:nValid+nOpt, :]\n",
        "OptImgs1 = TESTImgs1[nValid:nValid+nOpt, :]\n",
        "OptImgs2 = TESTImgs2[nValid:nValid+nOpt, :]\n",
        "OptImgs = np.concatenate((OptImgs0, OptImgs1, OptImgs2), axis=0)\n",
        "#OptLabels_1h\n",
        "OptLabels_1h0 = TESTLabels_1h0[nValid:nValid+nOpt, :]\n",
        "OptLabels_1h1 = TESTLabels_1h1[nValid:nValid+nOpt, :]\n",
        "OptLabels_1h2 = TESTLabels_1h2[nValid:nValid+nOpt, :]\n",
        "OptLabels_1h = np.concatenate((OptLabels_1h0, OptLabels_1h1, OptLabels_1h2), axis=0)\n",
        "#OptLabels\n",
        "OptLabels0 = TESTLabels0[nValid:nValid+nOpt]\n",
        "OptLabels1 = TESTLabels1[nValid:nValid+nOpt]\n",
        "OptLabels2 = TESTLabels2[nValid:nValid+nOpt]\n",
        "OptLabels = np.concatenate((OptLabels0, OptLabels1, OptLabels2), axis=0)\n",
        "\n",
        "#Optq------------------------------------------------------------ERRE nem lesz már szükség. ez hiba volt.\n",
        "#OptqImgs\n",
        "OptqImgs0 = TESTImgs0[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqImgs1 = TESTImgs1[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqImgs2 = TESTImgs2[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqImgs = np.concatenate((OptqImgs0, OptqImgs1, OptqImgs2), axis=0)\n",
        "#OptqLabels_1h\n",
        "OptqLabels_1h0 = TESTLabels_1h0[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqLabels_1h1 = TESTLabels_1h1[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqLabels_1h2 = TESTLabels_1h2[nValid+nOpt:nValid+nOpt+nOptq, :]\n",
        "OptqLabels_1h = np.concatenate((OptqLabels_1h0, OptqLabels_1h1, OptqLabels_1h2), axis=0)\n",
        "#OptqLabels\n",
        "OptqLabels0 = TESTLabels0[nValid+nOpt:nValid+nOpt+nOptq]\n",
        "OptqLabels1 = TESTLabels1[nValid+nOpt:nValid+nOpt+nOptq]\n",
        "OptqLabels2 = TESTLabels2[nValid+nOpt:nValid+nOpt+nOptq]\n",
        "OptqLabels = np.concatenate((OptqLabels0, OptqLabels1, OptqLabels2), axis=0)\n",
        "\n",
        "print \"_________________________________________________________________________________________________________________\"\n",
        "\n",
        "#Train\n",
        "ClassIndTrain=[]\n",
        "for c in train_nums: #not train_nums\n",
        "  c_class_indices_columnvector = np.argwhere(TrainLabels==float(c)) #visszaadja azon indeseket, ahol c classba tartozó elemek vannak\n",
        "  c_class_indices_rowvector = np.reshape(c_class_indices_columnvector, -1) #oszlopvektorból sorvektort csinál\n",
        "  ClassIndTrain.append(c_class_indices_rowvector)\n",
        "\n",
        "#Opt\n",
        "ClassIndOpt=[]\n",
        "for c in test_nums: #not train_nums\n",
        "  c_class_indices_columnvector = np.argwhere(OptLabels==float(c)) #visszaadja azon indeseket, ahol c classba tartozó elemek vannak\n",
        "  ClassIndOpt.append(np.reshape(c_class_indices_columnvector, -1))\n",
        "  \n",
        "#Valid\n",
        "ClassIndValid=[]\n",
        "for c in test_nums: #not train_nums\n",
        "  c_class_indices_columnvector = np.argwhere(ValidLabels==float(c)) #visszaadja azon indeseket, ahol c classba tartozó elemek vannak\n",
        "  ClassIndValid.append(np.reshape(c_class_indices_columnvector, -1))\n",
        "\n",
        "#Display ClassIndOpt\n",
        "for i in range(len(ClassIndOpt)):\n",
        "  print(str(test_nums[i]) + \"-esek indexei:\" + str(ClassIndOpt[i]))\n",
        "\n",
        "print OptqImgs\n",
        "print TESTLabels_1h1.shape\n",
        "print test_labels.shape\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 06:37:48.777698 139772578293632 deprecation.py:323] From <ipython-input-5-836f239a23d2>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0703 06:37:48.780087 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0703 06:37:48.781649 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0703 06:37:48.879635 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 06:37:49.213073 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0703 06:37:49.216769 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0703 06:37:49.323031 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "_________________________________________________________________________________________________________________\n",
            "7-esek indexei:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
            "8-esek indexei:[15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
            "9-esek indexei:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(3452, 3)\n",
            "(35000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgAyYsOLYJd5"
      },
      "source": [
        "##Graph\n",
        "A gráf csak 3 klasszú suprt setet tud kezelni. (Nem tudom, hogy lehet placeholder méretétől függővé tenni a neurhálók genrálását)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaK-OebAYJd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "4e2c427f-431f-4d22-b581-e9cd0fa6eb9d"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Support information - matrix\n",
        "s_imgs = tf.placeholder(tf.float32, [batchS, len(train_nums), nSupp]+size, name = \"s_imgs_ph\")   # batch size, n classes, n supp imgs / class\n",
        "\n",
        "# Query Information - vector\n",
        "q_img = tf.placeholder(tf.float32, [batchS]+size, name = \"q_img_ph\")    # batch size\n",
        "q_label = tf.placeholder(tf.int32, [batchS, len(train_nums)], name = \"q_label_ph\") # batch size, number of categories\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"### Network Function\n",
        "Call for each support image (row of the support matrix) and for the query image.\n",
        "\"\"\"\n",
        "\n",
        "def create_network(img, size, First = False):\n",
        "  currInp = img\n",
        "  layer = 0\n",
        "  currFilt = size[2]\n",
        "  \n",
        "  for k in nKernels:\n",
        "    with tf.variable_scope('conv'+str(layer), reuse = not First) as varscope:\n",
        "      layer += 1\n",
        "      weight = tf.get_variable('weight', [3,3,currFilt,k])   # make parameters!\n",
        "      currFilt = k\n",
        "      bias = tf.get_variable('bias', [k], initializer=tf.constant_initializer(0.0))\n",
        "      convR = tf.nn.conv2d(currInp, weight, strides=[1,1,1,1], padding=\"SAME\")\n",
        "      convR = tf.add(convR, bias)\n",
        "      reluR = tf.nn.relu(convR)\n",
        "      poolR = tf.nn.max_pool(reluR, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "      currInp = poolR\n",
        "  #add a fully connected at the end of the network this could modify the feature vector\n",
        "  with tf.variable_scope('FC', reuse = not First) as varscope:\n",
        "  \tCurrentShape=currInp.get_shape()\n",
        "\tFeatureLength = int(CurrentShape[1]*CurrentShape[2]*CurrentShape[3])\n",
        "\tFC = tf.reshape(currInp, [-1,FeatureLength])\n",
        "\tW = tf.get_variable('W',[FeatureLength,VectorLength])\n",
        "\tFC = tf.matmul(FC, W)\n",
        "\tBias = tf.get_variable('Bias',[VectorLength])\n",
        "\tFC = tf.add(FC, Bias)\n",
        "\tFC = tf.reshape(FC, [batchS,VectorLength,1,1])\n",
        "  return FC\n",
        "\n",
        "\n",
        "\n",
        "query_features = create_network(q_img, size, First = True)\n",
        "print query_features\n",
        "\n",
        "\n",
        "\n",
        "support_list = []\n",
        "query_list = []\n",
        "\n",
        "\n",
        "for k in range(len(train_nums)):#--------------------\n",
        "  slist=[]\n",
        "  qlist=[]\n",
        "  for i in range(nSupp):\n",
        "    slist.append(create_network(s_imgs[:, k, i, :, :, :], size))\n",
        "    qlist.append(query_features)\n",
        "  slist = tf.stack(slist)\n",
        "  qlist = tf.stack(qlist) \n",
        "  support_list.append(slist)\n",
        "  query_list.append(qlist)\n",
        "  \n",
        "query_repeat = tf.stack(query_list)\n",
        "supports = tf.stack(support_list)\n",
        "print query_repeat\n",
        "print supports\n",
        "\n",
        "\n",
        "\"\"\"### Loss\n",
        "Cosine distance calculation  \n",
        "Application of softmax  \n",
        "Minimize loss\n",
        "\"\"\"\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "  dotProduct = tf.reduce_sum(tf.multiply(query_repeat, supports), [3,4,5])\n",
        "  supportsMagn = tf.reduce_sum(tf.square(supports), [3,4,5])\n",
        "  #supportsMagn = tf.reduce_sum(tf.square(supports), [3,4,5])\n",
        "  cosDist = dotProduct / tf.clip_by_value(supportsMagn, 1e-10, float(\"inf\"))\n",
        "  print cosDist\n",
        "  # per support\n",
        "  cosDist = tf.transpose(cosDist,[2,0,1])\n",
        "  print cosDist\n",
        "  #meancosDist per class:\n",
        "  MeanCosDist= tf.reduce_mean(cosDist,2)\n",
        "  #maxcosDist per class:\n",
        "  MaxCostDist = tf.reduce_max(cosDist,2)\n",
        "\n",
        "\n",
        "  probs = tf.nn.softmax(MeanCosDist)  # defaults to last dimension\n",
        "\n",
        "  loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=MeanCosDist, labels=q_label))  # check if it's OK\n",
        "  print \"----------\"\n",
        "  print loss\n",
        "  \n",
        "  \n",
        "with tf.name_scope(\"optimizer\"):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "  \n",
        "\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "  max_class = tf.argmax(MaxCostDist, 1)\n",
        "  max_label = tf.argmax(q_label, 1)  \n",
        "  \n",
        "  total = tf.equal(max_class, max_label) \n",
        "  accuracy = tf.reduce_mean(tf.cast(total, tf.float32))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 06:37:50.189553 139772578293632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"FC/Reshape_1:0\", shape=(32, 16, 1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 06:37:50.686347 139772578293632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"stack_6:0\", shape=(3, 1, 32, 16, 1, 1), dtype=float32)\n",
            "Tensor(\"stack_7:0\", shape=(3, 1, 32, 16, 1, 1), dtype=float32)\n",
            "Tensor(\"loss/div:0\", shape=(3, 1, 32), dtype=float32)\n",
            "Tensor(\"loss/transpose:0\", shape=(32, 3, 1), dtype=float32)\n",
            "----------\n",
            "Tensor(\"loss/Sum_2:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8tUBiYLA2D_"
      },
      "source": [
        "#PROGRAM (optimalizálás, validálás)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmlw9C4UA2ED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "61f45bbc-17a2-434d-be35-1a60a02b1913"
      },
      "source": [
        "tpkezdet = time.time()\n",
        "for ProgIter in range(Iterations):\n",
        "  print ProgIter\n",
        "  print \"Minutes left: %s\" % ((Iterations-ProgIter)*(nOpt**3*3.081446019406528e-05/60+3.2))\n",
        "  '''New OptSet________________________________________________'''\n",
        "  d = nValid+nOpt+nOptq\n",
        "  #OptImgs\n",
        "  OptImgs0 = TESTImgs0[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs1 = TESTImgs1[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs2 = TESTImgs2[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs = np.concatenate((OptImgs0, OptImgs1, OptImgs2), axis=0)\n",
        "\n",
        "  '''____________________________________________________Optimalizaton_________________________________________________________________________________'''\n",
        "  '''__________________________________________________________________________________________________________________________________________________'''\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Used SET:\n",
        "  nums = test_nums\n",
        "  ClassIndices = ClassIndOpt\n",
        "  Imgs = OptImgs\n",
        "  Labels = OptLabels\n",
        "  Labels_1h = OptLabels_1h\n",
        "\n",
        "  #Reshape Sets to matrix shape (0. dim: CLASSes)\n",
        "  Imgs = np.reshape(Imgs, [len(nums), nOpt]+size)\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------------------\n",
        "  #Global variables:\n",
        "  ACCopt_full = []\n",
        "  ACCs_opt = []\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(session, \"model/234model\"+nulls+str(trainID_load)) #trainID_load = 00\n",
        "    It_steps = (nOpt**3)\n",
        "    ###print (\"\\nRun time: ~\" + str(It_steps*0.0068957/60) + \" min [\" + str(It_steps) + \"it]\\n\")\n",
        "\n",
        "    in_support = np.zeros([batchS, len(nums), nSupp]+size)\n",
        "    in_q = np.zeros([batchS]+size)\n",
        "    in_label = np.zeros([batchS, len(nums)])\n",
        "\n",
        "    Iter = 1\n",
        "    #in_support gen\n",
        "    for s0 in range(nOpt):\n",
        "      in_support[:,0,0,:,:,:] = batchS*[Imgs[0,s0,:,:,:]]\n",
        "      for s1 in range(nOpt):\n",
        "        in_support[:,1,0,:,:,:] = batchS*[Imgs[1,s1,:,:,:]]\n",
        "        for s2 in range(nOpt):\n",
        "          in_support[:,2,0,:,:,:] = batchS*[Imgs[2,s2,:,:,:]]\n",
        "\n",
        "          #TESTING of selected in_support\n",
        "          ACCs1SuppSet = []\n",
        "          for step in range(1): # egy 32es batch-ben lesz a tesztelés (össz 3*15-3=42 lehetőség lenne)\n",
        "            #in_q gen\n",
        "            in_label = np.zeros([batchS, len(nums)])\n",
        "            for bq in range(batchS):\n",
        "              q_class = np.random.choice(len(nums))\n",
        "              q_ind1class = np.random.choice(nOpt)\n",
        "              while((q_class == nums[0] and q_ind1class == s0) or\n",
        "                    (q_class == nums[1] and q_ind1class == s1) or\n",
        "                    (q_class == nums[2] and q_ind1class == s2)\n",
        "                   ):\n",
        "                q_class = np.random.choice(len(nums))\n",
        "                q_ind1class = np.random.choice(nOpt)\n",
        "              in_q[bq,:,:,:] = Imgs[q_class, q_ind1class, :,:,:]\n",
        "              in_label[bq, q_class] = 1\n",
        "\n",
        "            ACC, LOSS = session.run([accuracy, loss], feed_dict={s_imgs: in_support, q_img: in_q, q_label: in_label})\n",
        "\n",
        "            #if Iter%(It_steps/10) == 0:\n",
        "              #print(\"OptIter: \" + str(Iter) + \" /\" + str(nOpt**3))\n",
        "              ###print(\"ACC: %s\" % ACC)\n",
        "              ###print(\"----------------------\")\n",
        "            Iter += 1\n",
        "\n",
        "            ACCs1SuppSet.append(ACC)\n",
        "          ACCopt_full.append(ACCs1SuppSet)\n",
        "          ACCs_opt.append(np.average(ACCs1SuppSet))\n",
        "\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "  ###print \"Full running time: %s\" % ((t1-t0)/60) + \" min\"\n",
        "  ###print \"Running time / it_step: %s\" % ((t1-t0)/It_steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  '''BestSet Indices_____________________________________________________________________________________________________'''\n",
        "\n",
        "  ###print \"Opt:\"\n",
        "  ###print \"avg: %s\" % np.average(ACCs_opt) #0.84\n",
        "  ###print \"var: %s\" % np.var(ACCs_opt) #0.0017\n",
        "\n",
        "  ###print \"Full_var: %s\" % np.var(ACCopt_full) #0.0017\n",
        "  ###print \"---------------------\"\n",
        "  ###print \"Maxhely, érték: %s\" % ([ACCs_opt.index(max(ACCs_opt)), max(ACCs_opt)])\n",
        "\n",
        "  bestACC_opt = max(ACCs_opt)\n",
        "\n",
        "  nimgs = nOpt\n",
        "\n",
        "  #BestSetIndices\n",
        "  ind_img1 = ACCs_opt.index(max(ACCs_opt))/nimgs**2      # az eredeti indexet át kell váltani nimg-es számrendszerbe\n",
        "  ind_img2 = (ACCs_opt.index(max(ACCs_opt))-ind_img1*nimgs**2)/nimgs\n",
        "  ind_img3 = ACCs_opt.index(max(ACCs_opt))-ind_img1*nimgs**2-ind_img2*nimgs\n",
        "  BestSetIndices = [ind_img1, ind_img2, ind_img3]\n",
        "\n",
        "  #WorstSetIndices\n",
        "  ind_img1 = ACCs_opt.index(min(ACCs_opt))/nimgs**2\n",
        "  ind_img2 = (ACCs_opt.index(min(ACCs_opt))-ind_img1*nimgs**2)/nimgs\n",
        "  ind_img3 = ACCs_opt.index(min(ACCs_opt))-ind_img1*nimgs**2-ind_img2*nimgs\n",
        "  WorstSetIndices = [ind_img1, ind_img2, ind_img3]\n",
        "\n",
        "  ###print \"Maxhely, érték: %s\" % ([ACCs_opt.index(max(ACCs_opt)), max(ACCs_opt)])\n",
        "  ###print BestSetIndices\n",
        "  ###print \"Minhely, érték: %s\" % ([ACCs_opt.index(min(ACCs_opt)), min(ACCs_opt)])\n",
        "  ###print WorstSetIndices\n",
        "\n",
        "\n",
        "  '''________________________________________________VALIDATION________________________________________________________________________'''\n",
        "  '''_______________________________________________________________________________________________________________________________'''\n",
        "\n",
        "  '''Referency_____________________________________________________________________________________________________________________'''\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Used SET:\n",
        "  nums = test_nums\n",
        "  ClassIndices = ClassIndValid\n",
        "  Imgs = ValidImgs\n",
        "  Labels = ValidLabels\n",
        "  Labels_1h = ValidLabels_1h\n",
        "\n",
        "  #Reshape Sets to matrix shape (0. dim: CLASSes)\n",
        "  Imgs = np.reshape(Imgs, [len(nums), nValid]+size)\n",
        "  Labels = np.reshape(Labels, [len(nums), nValid])\n",
        "  Labels_1h = np.reshape(Labels_1h, [len(nums), nValid, len(nums)])\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------------------\n",
        "  #Global variables:\n",
        "  ACCs_Ref = []\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(session, \"model/234model\"+nulls+str(trainID_load))\n",
        "    ###print (\"\\nRun time: ~\" + str(ValidIter*0.006864/60) + \" min\")\n",
        "\n",
        "    in_support = np.zeros([batchS, len(nums), nSupp]+size)\n",
        "    in_q = np.zeros([batchS]+size)\n",
        "    in_label = np.zeros([batchS, len(nums)])\n",
        "\n",
        "    Iter = 1\n",
        "    #in_support gen\n",
        "    for b in range(batchS):\n",
        "      s0, s1, s2 = np.random.choice(np.arange(nValid), 3, replace = False)\n",
        "      in_support[b,0,0,:,:,:] = Imgs[0,s0,:,:,:]\n",
        "      in_support[b,1,0,:,:,:] = Imgs[1,s1,:,:,:]\n",
        "      in_support[b,2,0,:,:,:] = Imgs[2,s2,:,:,:]\n",
        "\n",
        "    #TESTING of selected in_support\n",
        "    ACCs1SuppSet = []\n",
        "    for step in range(ValidIter):\n",
        "      #in_q gen\n",
        "      in_label = np.zeros([batchS, len(nums)])\n",
        "      for bq in range(batchS):\n",
        "        while(True):\n",
        "          q_class = np.random.choice(len(nums))\n",
        "          q_ind1class = np.random.choice(nValid)\n",
        "          in_q[bq,:,:,:] = Imgs[q_class, q_ind1class, :,:,:]\n",
        "          #----------csak akkor lép ki a ciklusból, ha in_q különböző a supportoktól:\n",
        "          qImg_exists_in_support = False\n",
        "          for supp in  in_support[0, :, 0, :,:,:]:\n",
        "            if(np.array_equal(supp, in_q[bq,:,:,:])):\n",
        "              qImg_exists_in_support = True\n",
        "              break\n",
        "          if(qImg_exists_in_support == False):\n",
        "            break\n",
        "          #----------\n",
        "        in_label[bq, q_class] = 1\n",
        "\n",
        "      ACC, LOSS = session.run([accuracy, loss], feed_dict={s_imgs: in_support, q_img: in_q, q_label: in_label})\n",
        "\n",
        "      #if Iter%(ValidIter/5) == 0:\n",
        "        ###print(\"Iter: %s\" % Iter)\n",
        "        ###print(\"ACC: %s\" % ACC)\n",
        "        ###print(\"----------------------\")\n",
        "      Iter += 1\n",
        "\n",
        "      ACCs_Ref.append(ACC)\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "  ###print \"Full running time: %s\" % ((t1-t0)/60) + \" min\"\n",
        "  ###print \"Running time / it_step: %s\" % ((t1-t0)/ValidIter)\n",
        "\n",
        "\n",
        "  '''BestSet________________________________________________________________________________________________________________________'''\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Used SET:\n",
        "  nums = test_nums\n",
        "  ClassIndices = ClassIndValid\n",
        "  Imgs = ValidImgs\n",
        "  Labels = ValidLabels\n",
        "  Labels_1h = ValidLabels_1h\n",
        "\n",
        "  #Reshape Sets to matrix shape (0. dim: CLASSes)\n",
        "  Imgs = np.reshape(Imgs, [len(nums), nValid]+size)\n",
        "  Labels = np.reshape(Labels, [len(nums), nValid])\n",
        "  Labels_1h = np.reshape(Labels_1h, [len(nums), nValid, len(nums)])\n",
        "  Opt_imgs = np.reshape(OptImgs, [len(test_nums), nOpt]+size)\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------------------\n",
        "  #Global variables:\n",
        "  ACCs_Best = []\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(session, \"model/234model\"+nulls+str(trainID_load))\n",
        "    ###print (\"\\nRun time: ~\" + str(ValidIter*0.006864/60) + \" min\")\n",
        "\n",
        "    in_support = np.zeros([batchS, len(nums), nSupp]+size)\n",
        "    in_q = np.zeros([batchS]+size)\n",
        "    in_label = np.zeros([batchS, len(nums)])\n",
        "\n",
        "    Iter = 1\n",
        "    #in_support gen\n",
        "    for b in range(batchS):\n",
        "      s0, s1, s2 = BestSetIndices \n",
        "      in_support[b,0,0,:,:,:] = Opt_imgs[0,s0,:,:,:]\n",
        "      in_support[b,1,0,:,:,:] = Opt_imgs[1,s1,:,:,:]\n",
        "      in_support[b,2,0,:,:,:] = Opt_imgs[2,s2,:,:,:]\n",
        "\n",
        "    #TESTING of selected in_support\n",
        "    ACCs1SuppSet = []\n",
        "    for step in range(ValidIter):\n",
        "      #in_q gen\n",
        "      in_label = np.zeros([batchS, len(nums)])\n",
        "      for bq in range(batchS):\n",
        "        while(True):\n",
        "          q_class = np.random.choice(len(nums))\n",
        "          q_ind1class = np.random.choice(nValid)\n",
        "          in_q[bq,:,:,:] = Imgs[q_class, q_ind1class, :,:,:]\n",
        "          #----------csak akkor lépki a ciklusból, ha in_q különböző a supportoktól:\n",
        "          qImg_exists_in_support = False\n",
        "          for supp in  in_support[0, :, 0, :,:,:]:\n",
        "            if(np.array_equal(supp, in_q[bq,:,:,:])):\n",
        "              qImg_exists_in_support = True\n",
        "              break\n",
        "          if(qImg_exists_in_support == False):\n",
        "            break\n",
        "          #----------\n",
        "        in_label[bq, q_class] = 1\n",
        "\n",
        "      ACC, LOSS = session.run([accuracy, loss], feed_dict={s_imgs: in_support, q_img: in_q, q_label: in_label})\n",
        "\n",
        "      #if Iter%(ValidIter/5) == 0:\n",
        "        ###print(\"Iter: %s\" % Iter)\n",
        "        ###print(\"ACC: %s\" % ACC)\n",
        "        ###print(\"----------------------\")\n",
        "      Iter += 1\n",
        "\n",
        "      ACCs_Best.append(ACC)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "  ###print \"Full running time: %s\" % ((t1-t0)/60) + \" min\"\n",
        "  ###print \"Running time / it_step: %s\" % ((t1-t0)/ValidIter)\n",
        "\n",
        "\n",
        "  '''WorstSet________________________________________________________________________________________________________________________'''\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Used SET:\n",
        "  nums = test_nums\n",
        "  ClassIndices = ClassIndValid\n",
        "  Imgs = ValidImgs\n",
        "  Labels = ValidLabels\n",
        "  Labels_1h = ValidLabels_1h\n",
        "\n",
        "  #Reshape Sets to matrix shape (0. dim: CLASSes)\n",
        "  Imgs = np.reshape(Imgs, [len(nums), nValid]+size)\n",
        "  Labels = np.reshape(Labels, [len(nums), nValid])\n",
        "  Labels_1h = np.reshape(Labels_1h, [len(nums), nValid, len(nums)])\n",
        "  Opt_imgs = np.reshape(OptImgs, [len(test_nums), nOpt]+size)\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------------------\n",
        "  #Global variables:\n",
        "  ACCs_Worst = []\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(session, \"model/234model\"+nulls+str(trainID_load))\n",
        "    ###print (\"\\nRun time: ~\" + str(ValidIter*0.006864/60) + \" min\")\n",
        "\n",
        "    in_support = np.zeros([batchS, len(nums), nSupp]+size)\n",
        "    in_q = np.zeros([batchS]+size)\n",
        "    in_label = np.zeros([batchS, len(nums)])\n",
        "\n",
        "    Iter = 1\n",
        "    #in_support gen\n",
        "    for b in range(batchS):\n",
        "      s0, s1, s2 = WorstSetIndices \n",
        "      in_support[b,0,0,:,:,:] = Opt_imgs[0,s0,:,:,:]\n",
        "      in_support[b,1,0,:,:,:] = Opt_imgs[1,s1,:,:,:]\n",
        "      in_support[b,2,0,:,:,:] = Opt_imgs[2,s2,:,:,:]\n",
        "\n",
        "    #TESTING of selected in_support\n",
        "    ACCs1SuppSet = []\n",
        "    for step in range(ValidIter):\n",
        "      #in_q gen\n",
        "      in_label = np.zeros([batchS, len(nums)])\n",
        "      for bq in range(batchS):\n",
        "        while(True):\n",
        "          q_class = np.random.choice(len(nums))\n",
        "          q_ind1class = np.random.choice(nValid)\n",
        "          in_q[bq,:,:,:] = Imgs[q_class, q_ind1class, :,:,:]\n",
        "          #----------csak akkor lépki a ciklusból, ha in_q különböző a supportoktól:\n",
        "          qImg_exists_in_support = False\n",
        "          for supp in  in_support[0, :, 0, :,:,:]:\n",
        "            if(np.array_equal(supp, in_q[bq,:,:,:])):\n",
        "              qImg_exists_in_support = True\n",
        "              break\n",
        "          if(qImg_exists_in_support == False):\n",
        "            break\n",
        "          #----------\n",
        "        in_label[bq, q_class] = 1\n",
        "\n",
        "      ACC, LOSS = session.run([accuracy, loss], feed_dict={s_imgs: in_support, q_img: in_q, q_label: in_label})\n",
        "\n",
        "      #if Iter%(ValidIter/5) == 0:\n",
        "        ###print(\"Iter: %s\" % Iter)\n",
        "        ###print(\"ACC: %s\" % ACC)\n",
        "        ###print(\"----------------------\")\n",
        "      Iter += 1\n",
        "\n",
        "      ACCs_Worst.append(ACC)\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "  ###print \"Full running time: %s\" % ((t1-t0)/60) + \" min\"\n",
        "  ###print \"Running time / it_step: %s\" % ((t1-t0)/ValidIter)\n",
        "\n",
        "  '''###print AVG, VAR_________________________________________________________________________________________________'''\n",
        "\n",
        "  ###print \"AVG\"\n",
        "  ###print np.average(ACCs_Worst)\n",
        "  ###print np.average(ACCs_Ref)\n",
        "  ###print np.average(ACCs_Best)\n",
        "  ###print \"\"\n",
        "  ###print \"VAR\"\n",
        "  ###print np.var(ACCs_Worst)\n",
        "  ###print np.var(ACCs_Ref)\n",
        "  ###print np.var(ACCs_Best)\n",
        "\n",
        "  '''____________________S A V E_____________________________________________________________________________________________________'''\n",
        "\n",
        "  np.save(\"ACCs/ACCs_opt\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", ACCs_opt)\n",
        "  #np.save(\"ACCs/ACCs_Worst\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", ACCs_Worst)\n",
        "  #np.save(\"ACCs/ACCs_Ref\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", ACCs_Ref)\n",
        "  #np.save(\"ACCs/ACCs_Best\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", ACCs_Best)\n",
        "  np.save(\"ACCs/avg\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", [np.average(ACCs_Worst),\n",
        "                                                                                        np.average(ACCs_Ref),\n",
        "                                                                                        np.average(ACCs_Best)])\n",
        "  np.save(\"ACCs/var\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\", [np.var(ACCs_Worst),\n",
        "                                                                                        np.var(ACCs_Ref),\n",
        "                                                                                        np.var(ACCs_Best)])\n",
        "\n",
        "\n",
        "\n",
        "  '''FullTime'''\n",
        "  tVEG=time.time()\n",
        "  FullTime.append((tVEG-tKEZDET)/60)\n",
        "  ###print \"\\n\\nFULL TIME: %s\" % FullTime[-1] + \" min\"\n",
        "\n",
        "\n",
        "  '''______________________REPEAT Process_________________________________________________________'''\n",
        "  '''_____________________________________________________________________________________________'''\n",
        "  if changing == \"train\":\n",
        "    trainID += 1\n",
        "    trainID_load += 1\n",
        "  if changing == \"opt\":\n",
        "    OptID += 1\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nulls = \"\"\n",
        "  else:\n",
        "    nulls = \"0\"\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nullso = \"\"\n",
        "  else:\n",
        "    nullso = \"0\"\n",
        "\n",
        "    \n",
        "#Programidő mérése  \n",
        "tpveg=time.time()\n",
        "ProgTime = tpveg-tpkezdet\n",
        "print \"Program Time [min]: %s\" % (ProgTime/60)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "'''Init Download_________________________________________________________'''\n",
        "trainID = 0\n",
        "trainID_load = 0\n",
        "OptID = 0\n",
        "\n",
        "if 10 <= trainID:\n",
        "  nulls = \"\"\n",
        "else:\n",
        "  nulls = \"0\"\n",
        "if 10 <= OptID:\n",
        "  nullso = \"\"\n",
        "else:\n",
        "  nullso = \"0\"\n",
        "  \n",
        "  \n",
        "for i in range(Iterations):\n",
        "  '''Download'''\n",
        "  if download == True:\n",
        "    files.download(\"ACCs/ACCs_opt\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    #files.download(\"ACCs/ACCs_Worst\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    #files.download(\"ACCs/ACCs_Ref\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    #files.download(\"ACCs/ACCs_Best\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    files.download(\"ACCs/avg\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    files.download(\"ACCs/var\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    \n",
        "  '''______________________REPEAT Process_________________________________________________________'''\n",
        "  '''_____________________________________________________________________________________________'''\n",
        "  if changing == \"train\":\n",
        "    trainID += 1\n",
        "    trainID_load += 1\n",
        "  if changing == \"opt\":\n",
        "    OptID += 1\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nulls = \"\"\n",
        "  else:\n",
        "    nulls = \"0\"\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nullso = \"\"\n",
        "  else:\n",
        "    nullso = \"0\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Minutes left: 32.0173331339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0702 16:12:44.748706 139650784348032 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Minutes left: 28.8155998205\n",
            "2\n",
            "Minutes left: 25.6138665071\n",
            "3\n",
            "Minutes left: 22.4121331937\n",
            "4\n",
            "Minutes left: 19.2103998803\n",
            "5\n",
            "Minutes left: 16.0086665669\n",
            "6\n",
            "Minutes left: 12.8069332535\n",
            "7\n",
            "Minutes left: 9.60519994016\n",
            "8\n",
            "Minutes left: 6.40346662677\n",
            "9\n",
            "Minutes left: 3.20173331339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-be1c2abb2ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[0;34m'''Download'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ACCs/ACCs_opt\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnulls\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnOpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnullso\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ACCs/avg\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnulls\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnOpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnullso\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ACCs/var\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnulls\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnOpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnullso\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/files.pyc\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/output/_js.pyc\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx2gIpsJitZg"
      },
      "source": [
        "##Referency validáció újrafuttatása"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esbih97yhnP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "e695e1b9-6c71-4fed-994a-a80f76867c45"
      },
      "source": [
        "tpkezdet = time.time()\n",
        "\n",
        "for ProgIter in range(Iterations):\n",
        "  print ProgIter\n",
        "  print \"Minutes left: %s\" % ((Iterations-ProgIter)*(nOpt**3*3.081446019406528e-05/60+3.2))\n",
        "  \n",
        "  '''New OptSet________________________________________________'''\n",
        "  d = nValid+nOpt+nOptq\n",
        "  #OptImgs\n",
        "  OptImgs0 = TESTImgs0[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs1 = TESTImgs1[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs2 = TESTImgs2[d+OptID*nOpt : d+(OptID+1)*nOpt, :]\n",
        "  OptImgs = np.concatenate((OptImgs0, OptImgs1, OptImgs2), axis=0)\n",
        "  \n",
        "  #Reshape OptImgs to matrix shape (0. dim: CLASSes)\n",
        "  OptImgs = np.reshape(OptImgs, [len(nums), nOpt]+size)\n",
        "  \n",
        "\n",
        "  '''______________Validation -Referency____________________________________________________________________________'''\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Used SET:\n",
        "  nums = test_nums\n",
        "  ClassIndices = ClassIndValid\n",
        "  Imgs = ValidImgs\n",
        "  Labels = ValidLabels\n",
        "  Labels_1h = ValidLabels_1h\n",
        "\n",
        "  #Reshape Sets to matrix shape (0. dim: CLASSes)\n",
        "  Imgs = np.reshape(Imgs, [len(nums), nValid]+size)\n",
        "  Labels = np.reshape(Labels, [len(nums), nValid])\n",
        "  Labels_1h = np.reshape(Labels_1h, [len(nums), nValid, len(nums)])\n",
        "\n",
        "  #---------------------------------------------------------------------------------------------------------------------\n",
        "  #Global variables:\n",
        "  ACCs_Ref = []\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(session, \"model/234model\"+nulls+str(trainID_load))\n",
        "    ###print (\"\\nRun time: ~\" + str(ValidIter*0.006864/60) + \" min\")\n",
        "\n",
        "    in_support = np.zeros([batchS, len(nums), nSupp]+size)\n",
        "    in_q = np.zeros([batchS]+size)\n",
        "    in_label = np.zeros([batchS, len(nums)])\n",
        "\n",
        "    Iter = 1\n",
        "    #in_support gen\n",
        "    for b in range(batchS):\n",
        "      s0, s1, s2 = np.random.choice(np.arange(nOpt), 3, replace = False)\n",
        "      in_support[b,0,0,:,:,:] = OptImgs[0,s0,:,:,:]\n",
        "      in_support[b,1,0,:,:,:] = OptImgs[1,s1,:,:,:]\n",
        "      in_support[b,2,0,:,:,:] = OptImgs[2,s2,:,:,:]\n",
        "\n",
        "    #TESTING of selected in_support\n",
        "    ACCs1SuppSet = []\n",
        "    for step in range(ValidIter):\n",
        "      #in_q gen\n",
        "      in_label = np.zeros([batchS, len(nums)])\n",
        "      for bq in range(batchS):\n",
        "        while(True):\n",
        "          q_class = np.random.choice(len(nums))\n",
        "          q_ind1class = np.random.choice(nValid)\n",
        "          in_q[bq,:,:,:] = Imgs[q_class, q_ind1class, :,:,:]\n",
        "          #----------csak akkor lép ki a ciklusból, ha in_q különböző a supportoktól:\n",
        "          qImg_exists_in_support = False\n",
        "          for supp in  in_support[0, :, 0, :,:,:]:\n",
        "            if(np.array_equal(supp, in_q[bq,:,:,:])):\n",
        "              qImg_exists_in_support = True\n",
        "              break\n",
        "          if(qImg_exists_in_support == False):\n",
        "            break\n",
        "          #----------\n",
        "        in_label[bq, q_class] = 1\n",
        "\n",
        "      ACC, LOSS = session.run([accuracy, loss], feed_dict={s_imgs: in_support, q_img: in_q, q_label: in_label})\n",
        "\n",
        "      #if Iter%(ValidIter/5) == 0:\n",
        "        ###print(\"Iter: %s\" % Iter)\n",
        "        ###print(\"ACC: %s\" % ACC)\n",
        "        ###print(\"----------------------\")\n",
        "      Iter += 1\n",
        "\n",
        "      ACCs_Ref.append(ACC)\n",
        "\n",
        "\n",
        "  t1 = time.time()\n",
        "  ###print \"Full running time: %s\" % ((t1-t0)/60) + \" min\"\n",
        "  ###print \"Running time / it_step: %s\" % ((t1-t0)/ValidIter)\n",
        "  \n",
        "\n",
        "  '''______________________REPEAT Process_________________________________________________________'''\n",
        "  '''_____________________________________________________________________________________________'''\n",
        "  if changing == \"train\":\n",
        "    trainID += 1\n",
        "    trainID_load += 1\n",
        "  if changing == \"opt\":\n",
        "    OptID += 1\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nulls = \"\"\n",
        "  else:\n",
        "    nulls = \"0\"\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nullso = \"\"\n",
        "  else:\n",
        "    nullso = \"0\"\n",
        "    \n",
        "\n",
        "    \n",
        "'''FullTime'''\n",
        "tVEG=time.time()\n",
        "FullTime.append((tVEG-tKEZDET)/60)\n",
        "###print \"\\n\\nFULL TIME: %s\" % FullTime[-1] + \" min\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Minutes left: 32.0173331339\n",
            "2\n",
            "Minutes left: 25.6138665071\n",
            "3\n",
            "Minutes left: 22.4121331937\n",
            "4\n",
            "Minutes left: 19.2103998803\n",
            "5\n",
            "Minutes left: 16.0086665669\n",
            "6\n",
            "Minutes left: 12.8069332535\n",
            "7\n",
            "Minutes left: 9.60519994016\n",
            "8\n",
            "Minutes left: 6.40346662677\n",
            "9\n",
            "Minutes left: 3.20173331339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfukRhEloox0"
      },
      "source": [
        "\n",
        "OptImgs = np.reshape(OptImgs, [len(nums), nOpt]+size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xZ1BL33n0Fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2069c778-5130-4bed-ed1f-0710682b1804"
      },
      "source": [
        "OptImgs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 15, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iugcDCaHi7fW"
      },
      "source": [
        "###Save and Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHfAtvlshnBC"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2xfd9NWtixT"
      },
      "source": [
        "##Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPoeVB7Aak0p"
      },
      "source": [
        "'''Init Download_________________________________________________________'''\n",
        "trainID = 0\n",
        "trainID_load = 0\n",
        "OptID = 0\n",
        "\n",
        "if 10 <= trainID:\n",
        "  nulls = \"\"\n",
        "else:\n",
        "  nulls = \"0\"\n",
        "if 10 <= OptID:\n",
        "  nullso = \"\"\n",
        "else:\n",
        "  nullso = \"0\"\n",
        "  \n",
        "  \n",
        "for i in range(Iterations):\n",
        "  '''Download'''\n",
        "  if download == True:\n",
        "    files.download(\"ACCs/ACCs_opt\"+nulls+str(trainID)+\"_\"+str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    files.download(\"ACCs/avg\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    files.download(\"ACCs/var\"+nulls+str(trainID)+\"_\" + str(nOpt)+\"_\"+nullso+str(OptID)+\".npy\")\n",
        "    \n",
        "  '''______________________REPEAT Process_________________________________________________________'''\n",
        "  '''_____________________________________________________________________________________________'''\n",
        "  if changing == \"train\":\n",
        "    trainID += 1\n",
        "    trainID_load += 1\n",
        "  if changing == \"opt\":\n",
        "    OptID += 1\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nulls = \"\"\n",
        "  else:\n",
        "    nulls = \"0\"\n",
        "\n",
        "  if 10 <= trainID:\n",
        "    nullso = \"\"\n",
        "  else:\n",
        "    nullso = \"0\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ooqd3Ak1BiL"
      },
      "source": [
        "##Plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoHRdy2sEsa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "b36025d6-5c53-4141-eab5-02314268b152"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#load\n",
        "acc=[]\n",
        "avgW_opt, avgR_opt, avgB_opt = [], [], []\n",
        "for i in range(10):\n",
        "  #acc.append(np.load(\"ACCs_OptImgCombs\"+ str(i) +\"_5_5000.npy\"))\n",
        "  acc.append(np.load(\"ACCs/ACCs_opt00_15_0\"+ str(i) +\".npy\"))\n",
        "  avgW_opt.append(min(acc[i]))\n",
        "  avgR_opt.append(np.average(acc[i]))\n",
        "  avgB_opt.append(max(acc[i]))\n",
        "\n",
        "  \n",
        "  \n",
        "avgW, avgR, avgB = [], [], []\n",
        "for i in range(10):\n",
        "  WRB = np.load(\"ACCs/avg00_15_0\"+ str(i) +\".npy\")\n",
        "  avgW.append(WRB[0])\n",
        "  avgR.append(WRB[1])\n",
        "  avgB.append(WRB[2])\n",
        "  \n",
        "#convert\n",
        "'''\n",
        "for i in range(10):\n",
        "  avgW.append(avg[i][0])\n",
        "  avgR.append(avg[i][1])\n",
        "  avgB.append(avg[i][2])\n",
        "'''\n",
        "\n",
        "#plot\n",
        "plt.hold(True)\n",
        "\n",
        "plt.bar(range(10), avgB, color = 'g')\n",
        "plt.bar(range(10), avgR, color = 'y')\n",
        "plt.bar(range(10), avgW, color = 'r' )\n",
        "\n",
        "#plt.plot(avgR)\n",
        "#plt.plot(avgW)\n",
        "\n",
        "plt.xlabel('Different optimalization sets')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "#plt.plot(np.zeros(10))\n",
        "#plt.plot(np.ones(10))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#Prints:\n",
        "print np.argmax(acc[9])\n",
        "print acc[9][616]\n",
        "i = 616\n",
        "_100 = i/15**2\n",
        "_10 = (i-_100*15**2)/15\n",
        "_1 = (i-_100*15**2-_10*15)\n",
        "i2 = _100*100+_10*10+_1\n",
        "print i2\n",
        "print avgB[4]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:32: MatplotlibDeprecationWarning: pyplot.hold is deprecated.\n",
            "    Future behavior will be consistent with the long-time default:\n",
            "    plot commands add elements without first clearing the\n",
            "    Axes and/or Figure.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUlSx1CQJHUMBUlSx1CQJHX+P7PwDhMeCS27AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "616\n",
            "1.0\n",
            "311\n",
            "0.75273126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yaclh1l1sqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "54f2d875-b06a-4a57-fd56-fd03328197e7"
      },
      "source": [
        "accWRB = [ACCs_Worst, ACCs_Ref, ACCs_Best]\n",
        "len(accWRB[0])\n",
        "\n",
        "BestInds = np.ndarray([10,3], dtype = int)\n",
        "for i in range(10):\n",
        "  ind = np.argmax(acc[i])\n",
        "  BestInds[i,0] = ind/15**2\n",
        "  BestInds[i,1] = (ind-BestInds[i,0]*15**2)/15\n",
        "  BestInds[i,2] = ind-BestInds[i,0]*15**2-BestInds[i,1]*15\n",
        "\n",
        "  \n",
        "#PRINT\n",
        "for i in range(10):\n",
        "  print str(i) + \" BestAcc: \" + str(avgB[i]) + \"    BestInd: \"+ str(BestInds[i])\n",
        "  \n",
        "  \n",
        "print BestInds\n",
        "\n",
        "\n",
        "# [4] -es opthalmaz, [2, 12, 8] indexű a legjobb. (acc= 0.7527)\n",
        "\n",
        "#[0]-ás opthalmazból:"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 BestAcc: 0.7312    BestInd: [ 2 10  8]\n",
            "1 BestAcc: 0.741025    BestInd: [2 4 0]\n",
            "2 BestAcc: 0.7282063    BestInd: [ 5  5 12]\n",
            "3 BestAcc: 0.7382563    BestInd: [9 8 0]\n",
            "4 BestAcc: 0.75273126    BestInd: [ 2 12  8]\n",
            "5 BestAcc: 0.71709377    BestInd: [ 7  0 12]\n",
            "6 BestAcc: 0.74070626    BestInd: [0 3 0]\n",
            "7 BestAcc: 0.7489188    BestInd: [ 7 11  2]\n",
            "8 BestAcc: 0.7141687    BestInd: [3 0 0]\n",
            "9 BestAcc: 0.6755813    BestInd: [ 2 11  1]\n",
            "[[ 2 10  8]\n",
            " [ 2  4  0]\n",
            " [ 5  5 12]\n",
            " [ 9  8  0]\n",
            " [ 2 12  8]\n",
            " [ 7  0 12]\n",
            " [ 0  3  0]\n",
            " [ 7 11  2]\n",
            " [ 3  0  0]\n",
            " [ 2 11  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4YWJAuzAcoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "72823e1a-012a-4e4c-99cf-3fe8ad55d720"
      },
      "source": [
        "BestInds = np.ndarray([10,3], dtype = int)\n",
        "for i in range(10):\n",
        "  ind = np.argmin(acc[i])\n",
        "  BestInds[i,0] = ind/15**2\n",
        "  BestInds[i,1] = (ind-BestInds[i,0]*15**2)/15\n",
        "  BestInds[i,2] = ind-BestInds[i,0]*15**2-BestInds[i,1]*15\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0186497c3217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBestInds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mBestInds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mBestInds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mBestInds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSeDZtvRJoZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}